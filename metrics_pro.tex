\documentclass[11pt, a4paper]{article}

% If you can't see cyrillic letters in R-studio choose
% File-Reopen with encoding
% utf8 is the preferred encoding


\input{title_bor_utf8_knitr}
\input{emetrix_preamble}




\usepackage[bibencoding = auto, backend = biber,
sorting = none]{biblatex}

\addbibresource{metrics_pro.bib}

\def \RR{\mathbb{R}}
\def \cN{\mathcal{N}}
\def \htheta{\hat{\theta}}

\title{Заметки к семинарам по эконометрике}
\author{Винни-Пух}
\date{\today}


% делаем короче интервал в списках
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}


\DeclareMathOperator{\Med}{Med}


\usepackage{answers} % дележка условий и ответов

%\newtheorem{problem}{Задача}
%\numberwithin{problem}{section}

\Newassociation{sol}{solution}{solution_file}
% sol — имя окружения внутри задач
% solution — имя окружения внутри solution_file
% solution_file — имя файла в который будет идти запись решений
% можно изменить далее по ходу
\Opensolutionfile{solution_file}[all_solutions]
% в квадратных скобках фактическое имя файла


% магия для автоматических гиперссылок задача-решение
\newlist{myenum}{enumerate}{3}
% \newcounter{problem}[chapter] % нумерация задач внутри глав
\newcounter{problem}[section]

\newenvironment{problem}%
{%
\refstepcounter{problem}%
%  hyperlink to solution
     \hypertarget{problem:{\thesection.\theproblem}}{} % нумерация внутри глав
     % \hypertarget{problem:{\theproblem}}{}
     \Writetofile{solution_file}{\protect\hypertarget{soln:\thesection.\theproblem}{}}
     %\Writetofile{solution_file}{\protect\hypertarget{soln:\theproblem}{}}
     \begin{myenum}[label=\bfseries\protect\hyperlink{soln:\thesection.\theproblem}{\thesection.\theproblem},ref=\thesection.\theproblem]
     % \begin{myenum}[label=\bfseries\protect\hyperlink{soln:\theproblem}{\theproblem},ref=\theproblem]
     \item%
    }%
    {%
    \end{myenum}}
% для гиперссылок обратно надо переопределять окружение
% это происходит непосредственно перед подключением файла с решениями





\begin{document}

% \maketitle % ставим сюда название, автора и время создания

\section{МНК — это\ldots}

Минитеория:

\begin{enumerate}
\item Истинная модель. Например, $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + u_i$.
\item Формула для прогнозов. Например, $\hy_i = \hb_1 + \hb_2 x_i + \hb_3 z_i$.
\item Метод наименьших квадратов, $\sum (y_i - \hy_i)^2 \to \min$.
\end{enumerate}

Задачи:
\begin{problem}
Каждый день Маша ест конфеты и решает задачи по эконометрике. Пусть $x_i$ — количество решённых задач, а $y_i$ — количество съеденных конфет.

\begin{tabular}{cc}
\toprule
$x_i$ & $y_i$ \\
\midrule
1 & 1 \\
2 & 2 \\
2 & 4 \\
\bottomrule
\end{tabular}

\begin{enumerate}
\item Рассмотрим модель $y_i = \beta x_i + u_i$:
\begin{enumerate}
\item Найдите МНК-оценку $\hb$ для имеющихся трёх наблюдений.
\item Нарисуйте исходные точки и полученную прямую регрессии.
\item Выведите формулу для $\hb$ в общем виде для $n$ наблюдений.
\end{enumerate}

\item Рассмотрим модель $y_i = \beta_1 + \beta_2 x_i + u_i$:
\begin{enumerate}
\item Найдите МНК-оценки $\hb_1$ и $\hb_2$ для имеющихся трёх наблюдений.
\item Нарисуйте исходные точки и полученную прямую регрессии.
\item Выведите формулу для $\hb_2$ в общем виде для $n$ наблюдений.
\end{enumerate}

\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Упростите выражения:
\begin{enumerate}
\item $n\bar x - \sum x_i$
\item $\sum (x_i - \bar x)\bar x$
\item $\sum (x_i - \bar x)\bar z$
\item $\sum (x_i - \bar x)^2 + n \bar{x}^2$
\end{enumerate}

\begin{sol}
Ответы: $0$, $0$, $0$, $\sum x_i^2$.
\end{sol}
\end{problem}


\begin{problem}
При помощи метода наименьших квадратов найдите оценку неизвестного параметра $\theta$ в следующих моделях:

\begin{enumerate}
\item $y_i = \theta + \theta x_i + \varepsilon_i$;
\item $y_i = 1 + \theta x_i + \e_i$;
\item $y_i = \theta / x_i + \e_i$;
\item $y_i = \theta x_i + (1-\theta)z_i+\e_i$.
\end{enumerate}

\begin{sol}
\begin{enumerate}
\item \(\htheta = \sum \left((y_i - z_i)(x_i - z_i) \right) / \sum \left(x_i - z_i\right)^2 \)
\end{enumerate}
\end{sol}
\end{problem}

\begin{problem}
Найдите МНК-оценки параметров $\alpha$ и $\beta$ в модели $y_i = \alpha + \beta y_i + \e_i$.


\begin{sol}
\(\hat{\alpha} = 0, \ \hb = 1 \)
\end{sol}
\end{problem}


\begin{problem}
Рассмотрите модели $y_i = \alpha + \beta (y_i + z_i) + \e_i$, $z_i = \gamma + \delta(y_i+z_i) + \e_i$.
\begin{enumerate}
\item Как связаны между собой $\hat{\alpha}$ и $\hat{\gamma}$?
\item Как связаны между собой $\hb$ и $\hat{\delta}$?
\end{enumerate}


\begin{sol} % 1.5.
Рассмотрим регрессию суммы $(y_i + z_i)$ на саму себя. Естественно, в ней
\[
\widehat{y_i + z_i} = 0 + 1 \cdot (y_i + z_i).
\]

Отсюда получаем, что $\hat{\alpha} + \hat{\gamma} = 0$ и $\hb + \hat{\delta} = 1$.
\end{sol}
\end{problem}




\begin{problem}
Как связаны МНК-оценки параметров $\alpha, \beta$ и $\gamma, \delta$ в моделях $y_i = \alpha + \beta x_i + \e_i$ и $z_i = \gamma + \delta x_i + \upsilon_i$, если $z_i = 2 y_i$?


\begin{sol}

Исходя из условия, нужно оценить методом МНК коэффициенты двух следующих моделей:
\[y_i = \alpha + \beta x_i + \e_i \]
\[y_i = \frac{\gamma}{2} + \frac{\delta}{2} x_i + \frac{1}{2} v_i \]

Заметим, что на минимизацию суммы квадратов остатков коэффициент \(1/2\) не влияет, следовательно:
\[\hat{\gamma} = 2\hat{\alpha}, \ \hat{\delta} = 2 \hb  \]

\end{sol}
\end{problem}


\begin{problem}
Для модели $y_i = \beta_1 x_i + \beta_2 z_i + \e_i$ решите условную задачу о наименьших квадратах:
\[
Q(\beta_1, \beta_2) := \sum_{i=1}^n (y_i - \hb_1 x_i - \hb_2 z_i)^2 \rightarrow \underset{\beta_1 + \beta_2 = 1}{\min}.
\]


\begin{sol}
Выпишем задачу:
\[
\begin{cases}
RSS = \sum\limits_{i=1}^{n}(y_i - \hb_1x_i - \hb_2z_i)^2 \rightarrow \min\limits_{\hb_1, \hb_2}\\
\hb_1 + \hb_2 = 1
\end{cases}
\]

Можем превратить ее в задачу минимизации функции одного аргумента:
\[
RSS =  \sum\limits_{i=1}^{n}(y_i - x_i - \hb_2(z_i-x_i))^2 \rightarrow \min_{\hb_2}
\]

Выпишем условия первого порядка:
\[
\frac{\partial RSS}{\partial \hb_2} = \sum\limits_{i=1}^{n}2(y_i-x_i-\hb_2(z_i-x_i))(x_i-z_i)=0
\]

Отсюда:
\[
\sum\limits_{i=1}^{n}(y_i-x_i)(x_i-z_i) + \hb_2\sum\limits_{i=1}^{n}(z_i-x_i)^2 = 0 \Rightarrow \hb_2 = \frac{\sum\limits_{i=1}^n (y_i-x_i)(z_i-x_i)}{\sum\limits_{i=1}^n (z_i-x_i)^2}
\]

А $\hb_1$ найдется из соотношения $\hb_1+\hb_2 = 1$.

\end{sol}
\end{problem}

\begin{problem}
Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток — $200$ грамм, взвесив оба слитка — $400$ грамм. Оцените вес каждого слитка методом наименьших квадратов.

\begin{sol}
Обозначив вес первого слитка за \(\beta_1\), вес второго слитка за \(\beta_2\), а показания весов за \(y_i\), получим, что
\[y_1 = \beta_1 + \e_1, \ y_2 = \beta_2 + \e_2, \ y_3 = \beta_1 + \beta_2 + \e_3\]

Тогда
\[(300 - \beta_1)^2 + (200 - \beta_2)^2 + (400 - \beta_1 - \beta_2)^2 \rightarrow \min \limits_{\beta_1,\  \beta_2} \]
\[\hb_1 = \frac{800}{3}, \ \hb_2 = \frac{500}{3} \]
\end{sol}
\end{problem}


\begin{problem}
Аня и Настя утверждают, что лектор опоздал на 10 минут. Таня считает, что лектор опоздал на 3 минуты. С помощью МНК оцените, на сколько опоздал лектор.

\begin{sol}
Можем воспользоваться готовой формулой для регрессии на константу:
\[
\hb = \bar{y} = \frac{10+10+3}{3} = \frac{23}{3}
\]

(можно решить задачу $2(10-\beta)^2 + (3-\beta)^2\rightarrow \min$)

\end{sol}
\end{problem}

\begin{problem}
Есть двести наблюдений. Вовочка оценил модель $\hy=\hb_1+\hb_2 x$ по первой сотне наблюдений. Петечка оценил модель $\hy=\hat{\gamma}_1+\hat{\gamma}_2 x$ по второй сотне наблюдений. Машенька оценила модель $\hy=\hat{m}_1+\hat{m}_2 x$ по всем наблюдениям.
\begin{enumerate}
\item Возможно ли, что $\hb_2>0$, $\hat{\gamma}_2>0$, но $\hat{m}_2<0$?
\item Возможно ли, что $\hb_1>0$, $\hat{\gamma}_1>0$, но $\hat{m}_1<0$?
\item Возможно ли одновременное выполнение всех упомянутых условий?
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}

Эконометрист Вовочка собрал интересный набор данных по студентам третьего курса:
\begin{itemize}
\item переменная $y_i$ — количество пирожков, съеденных $i$-ым студентом за прошлый год;
\item переменная $f_i$, которая равна 1, если $i$-ый человек в выборке — женщина, и 0, если мужчина.
\item переменная\footnote{Это нетолерантная задача и здесь либо $f$ равно 1, либо $m$} $m_i$, которая равна 1, если $i$-ый человек в выборке — мужчина, и 0, если женщина.
\end{itemize}

Вовочка попробовал оценить 4 регрессии:
\begin{enumerate}
\item[A:] $y$ на константу и $f$;
\item[B:] $y$ на константу и $m$;
\item[C:] $y$ на $f$ и $m$ без константы;
\item[D:] $y$ на константу, $f$ и $m$.
\end{enumerate}

\begin{enumerate}
\item Какой смысл будут иметь оцениваемые коэффициенты?
\item Как связаны между собой оценки коэффициентов этих регрессий?
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Эконометрист Вовочка оценил методом наименьших квадратов модель 1, $y=\b_1+\b_2 x+\b_3 z+\e$, а затем модель 2, $y=\b_1+\b_2 x+\b_3 z+\b_4 w+\e$. Сравните полученные $ESS$, $RSS$, $TSS$ и $R^2$.

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Что происходит с $TSS$, $RSS$, $ESS$, $R^2$ при добавлении нового наблюдения? Если величина может изменяться только в одну сторону, то докажите это. Если возможны и рост, и падение, то приведите пример.


\begin{sol}
Пусть \(\bar{y}\) — средний \(y\) до добавления нового наблюдения, \(\bar{y}'\) — после добавления нового наблюдения. Будем считать, что изначально было \(n\) наблюдений. Заметим, что
\[\bar{y}' = \frac{(y_1 + \ldots + y_n) + y_{n+1}}{n + 1} = \frac{n \bar{y} + y_{n + 1}}{n + 1} = \frac{n}{n+ 1}\bar{y} + \frac{1}{n+1}y_{n+1}\]

Покажем, что \(TSS\) может только увеличится при добавлении нового наблюдения (остается неизменным при \(y_{n+1} = \bar{y}\)):
\[TSS'= \sum_{i = 1}^{n + 1} (y_i - \bar{y}')^2 = \sum_{i = 1}^{n} (y_i - \bar{y} + \bar{y} - \bar{y}')^2 + (y_{n + 1} - \bar{y}')^2 = \]
\[=\sum_{i = 1}^{n} (y_i - \bar{y})^2 + n(\bar{y} - \bar{y}')^2 + (y_{n + 1} - \bar{y}')^2  = TSS + \frac{n}{n+1} (y_{n+1} - \bar{y})^2\]

Следовательно, \(TSS' \geqslant TSS\).

Также сумма \(RSS\) может только вырасти или остаться постоянной при добавлении нового наблюдения. Действительно, новое $(n+1)$-ое слагаемое в сумме неотрицательно. А сумма $n$ слагаемых минимальна при старых коэффициентах, а не при новых.

\(ESS\) и \(R^2\) могут меняться в обе стороны. Например, рассмотрим ситуацию, где точки лежат симметрично относительно некоторой горизонтальной прямой. При этом $ESS=0$. Добавим наблюдение — $ESS$ вырастет, удалим наблюдение — $ESS$ вырастет.
\end{sol}
\end{problem}



\begin{problem}
Эконометресса Аглая подглядела, что у эконометрессы Жозефины получился $R^2$ равный $0.99$ по 300 наблюдениям. От чёрной зависти Аглая не может ни есть, ни спать.

\begin{enumerate}
\item Аглая добавила в набор данных Жозефины ещё 300 наблюдений с такими же регрессорами, но противоположными по знаку игреками, чем были у Жозефины. Как изменится $R^2$?
\item Жозефина заметила, что Аглая добавила 300 наблюдений и вычеркнула их, вернув в набор данных в исходное состояние. Хитрая Аглая решила тогда добавить всего одно наблюдение так, чтобы $R^2$ упал до нуля. Удастся ли ей это сделать?
\end{enumerate}


\begin{sol}
\begin{enumerate}
\item $R^2$ упал до нуля.
\item Да, можно. Если добавить точку далеко слева внизу от исходного набора данных, то наклон линии регрессии будет положительный. Если далеко справа внизу, то отрицательный. Будем двигать точку так, чтобы поймать нулевой наклон прямой. Получим $ESS=0$.
\end{enumerate}
\end{sol}
\end{problem}


\begin{problem}
На работе Феофан построил парную регрессию по трём наблюдениям и посчитал прогнозы $\hat{y}_i$. Придя домой он отчасти вспомнил результаты:

\begin{tabular}{rr}
\toprule
$y_i$ & $\hy_i$ \\
\midrule
$0$ & $1$ \\
$6$ & ? \\
$6$ & ? \\
\bottomrule
\end{tabular}

Поднапрягшись, Феофан вспомнил, что третий прогноз был больше второго. Помогите Феофану восстановить пропущенные значения.


\begin{sol}
На две неизвестных $a$ и $b$ нужно два уравнения. Эти два уравнения — ортогональность вектора остатков плоскости регрессоров. А именно:

\[
\begin{cases}
\sum_i (y_i - \hy_i) = 0 \\
\sum_i (y_i - \hy_i) \hy_i = 0 \\
\end{cases}
\]

В нашем случае

\[
\begin{cases}
-1 +(6-a) + (6-b) = 0 \\
-1 + (6 - a)a + (6-b)b = 0 \\
\end{cases}
\]

Решаем квадратное уравнение и получаем два решения: $a=4$ и $a=7$. Итого: $a=4$, $b=7$.
\end{sol}
\end{problem}


\begin{problem}
Вся выборка поделена на две части. Возможны ли такие ситуации:
\begin{enumerate}
    \item Выборочная корреляция между $y$ и $x$ примерно равна нулю в каждой части, а по всей выборке примерно равна единице;
    \item Выборочная корреляция между $y$ и $x$ примерно ранва единице в каждой части, а по всей выборке примерно равна нулю?
\end{enumerate}

\begin{sol}
Обе ситуации возможны.
\end{sol}
\end{problem}

\section{Дифференциал — просто няшка!}

Минитеория.

Дифференциал для матриц подчиняется правилам:

\begin{enumerate}
\item $da = 0$, $dA = 0$;
\item $d(RS) = dR \dot S + R \cdot dS$
\end{enumerate}



\begin{problem}
    Вспомним дифференциал :)
    \begin{enumerate}
        \item Известно, что $f(x) = x^2 + 3x$. Найдите $f'(x)$ и $df$. Чему равен $dx$ в точке $x=5$ при $dx=0.1$?
        \item Известно, что $f(x_1, x_2)=x_1^2 + 3x_1x_2^3$. Найдите $df$. Чему равен $df$ в точке $x_1=-2$, $x_2=1$ при $dx_1=0.1$ и $dx_2=-0.1$?
        \item Известно, что $F=\begin{pmatrix}
                5 & 6x_1 \\
                x_1x_2 & x_1^2x_2 \\
            \end{pmatrix}$. Найдите $dF$.
        \item Известно, что $F=\begin{pmatrix}
                7 & 8 & 9 \\
                2 & -1 & -2 \\
            \end{pmatrix}$. Найдите $dF$.
        \item Матрица $F$ имеет размер $2\times 2$, в строке $i$ столбце $j$ у неё находится элемент $f_{ij}$.
            Выпишите выражение $\tr(F'dF)$ в явном виде без матриц.
    \end{enumerate}
\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Пусть $t$ — скалярная переменная, $r$, $s$ — векторные переменные, $R$, $S$ — матричные переменные. Кроме того, $a$, $b$ — векторы констант, $A$, $B$ — матрицы констант.

Применив базовые правила дифференцирования найдите:
\begin{enumerate}
\item $d(ARB)$;
\item $d(r'r)$;
\item $d(r'Ar)$;
\item $d(R^{-1})$, воспользовавшись тем, что $R^{-1} \cdot R = I$;
\item $d \cos(r'r)$;
\item $d(r'Ar/r'r)$.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
В методе наименьших квадратов минимизируется функция
\[
Q(\hb) = (y - X\hb)'(y - X\hb).
\]

\begin{enumerate}
\item Найдите $dQ(\hb)$ и $d^2Q(\hb)$;
\item Выпишите условия первого порядка для задачи МНК;
\item Выразите $\hb$ предполагая, что $X'X$ обратима.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
В методе LASSO минимизируется функция
\[
Q(\hb) = (y - X\hb)'(y - X\hb) + \lambda \hb' \hb,
\]
где $\lambda$ — положительный параметр, штрафующий функцию за слишком большие значения $\hb$.

\begin{enumerate}
\item Найдите $dQ(\hb)$ и $d^2Q(\hb)$;
\item Выпишите условия первого порядка для задачи LASSO;
\item Выразите $\hb$.
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}

\section{МНК в матрицах и геометрия!}


% 4.13
\begin{problem}
Пусть $y_i = \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \e_i$ — регрессионная модель, где $X = \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \\ 1 & 1 & 0 \\ 1 & 1 & 1 \end{pmatrix}$, $y = \begin{pmatrix} 1 \\ 2 \\ 3 \\ 4 \\ 5 \end{pmatrix}$, $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \end{pmatrix}$, $\e = \begin{pmatrix} \e_1 \\ \e_2 \\ \e_3 \\ \e_4 \\ \e_5  \end{pmatrix}$, ошибки $\e_i$ независимы и нормально распределены с $\E(\e)$ = 0, $Var(\e) = \sigma^2 I$. Для удобства расчётов даны матрицы: $X'X = \begin{pmatrix} 5 & 2 & 1 \\ 2 & 2 & 1\\ 1 & 1 & 1 \end{pmatrix}$ и $(X'X)^{-1}= \begin{pmatrix} 0.3333 & -0.3333 & 0.0000 \\ -0.3333 & 1.3333 & -1.0000 \\ 0.0000 & -1.0000 & 2.0000 \end{pmatrix}$


\begin{enumerate}
\item Укажите число наблюдений.
\item Укажите число регрессоров в модели, учитывая свободный член.
\item Найдите $TSS = \sum_{i=1}^n (y_i - \bar y)^2$.
\item Найдите $RSS = \sum_{i=1}^n (y_i - \hy_i)^2$.
\item Методом МНК найдите оценку для вектора неизвестных коэффициентов.
\item Чему равен $R^2$ в модели? Прокомментируйте полученное значение с точки зрения качества оценённого уравнения регрессии.\end{enumerate}
\begin{sol}

\begin{enumerate}
\item $n = 5$
\item $k = 3$
\item $TSS = 10$
\item $RSS = 2$
\item $\hb = \begin{pmatrix} \hb_1 \\ \hb_2 \\ \hb_3 \end{pmatrix} = (X'X)^{-1}X'y = \begin{pmatrix} 2 \\ 2 \\ 1 \end{pmatrix}$
\item $R^2 = 1 - \frac {RSS}{TSS} = 0.8.$ $R^2$ высокий, построенная эконометрическая модель хорошо описывает данные
\end{enumerate}
\end{sol}
\end{problem}



\begin{problem}
Найдите на картинке все перпендикулярные векторы. Найдите на картинке все прямоугольные треугольники. Сформулируйте для них теоремы Пифагора.

\tdplotsetmaincoords{70}{110}
\begin{tikzpicture}[tdplot_main_coords]
\coordinate (hY) at (0,2.7,0);
\coordinate (Y) at (-2,2,2);
\coordinate (bY) at (-2,1,0);
\draw[thick,dotted, ->] (0,0,0) -- (-4,2,0) node[anchor=west]{$\vec{1}$};
\draw[thick,->] (0,0,0) -- (hY) node[anchor=west]{$\hy$};
\draw[thick,->] (0,0,0) -- (Y) node[anchor=south]{$y$};
\draw[thick,->] (0,0,0) -- (1,2,0) node[anchor=north]{$x$};
\draw[dotted] (hY) -- (Y);
\draw[dotted] (hY) -- (bY);
\draw[dotted] (Y) -- (bY);
\draw[thick,->] (0,0,0) -- (bY) node[anchor=south]{$\bar{y}\cdot \vec{1}$};
\end{tikzpicture}





\begin{sol}
$\sum y_i^2=\sum \hy_i^2+\sum \he_i^2$, $TSS=ESS+RSS$,
\end{sol}
\end{problem}



\begin{problem}
Покажите на картинке TSS, ESS, RSS, $R^2$, $\sCorr(\hy,y)$, $\sCov(\hy,y)$

\tdplotsetmaincoords{70}{110}
\begin{tikzpicture}[tdplot_main_coords]
\coordinate (hY) at (0,2.7,0);
\coordinate (Y) at (-2,2,2);
\coordinate (bY) at (-2,1,0);
\draw[thick,dotted, ->] (0,0,0) -- (-4,2,0) node[anchor=west]{$\vec{1}$};
\draw[thick,->] (0,0,0) -- (hY) node[anchor=west]{$\hy$};
\draw[thick,->] (0,0,0) -- (Y) node[anchor=south]{$y$};
\draw[thick,->] (0,0,0) -- (1,2,0) node[anchor=north]{$x$};
\draw[dotted] (hY) -- (Y);
\draw[dotted] (hY) -- (bY);
\draw[dotted] (Y) -- (bY);
\draw[thick,->] (0,0,0) -- (bY) node[anchor=south]{$\bar{y}\cdot \vec{1}$};
\end{tikzpicture}




\begin{sol}
$\sCorr(\hy, y)=\frac{\sCov(\hy, y)}{\sqrt{\sVar(\hy)\sVar{(y)}}}$

$\sCorr(\hy, y)^2=\frac{(\sCov(\hy, y))^2}{\sVar(\hy)\sVar{(y)}} $

$R^2\cdot TSS/(n-1)\cdot ESS/(n-1)=(\sCov(\hy, y))^2=(\sCov(\hy-\bar y, y-\bar y))^2$
Отсюда можно понять, что ковариация для двухмерного случая равна произведению длин векторов $\hy-\bar y$ и $y-\bar y$ — $\sqrt{ESS}$ и $\sqrt{TSS}$ на косинус угла между ними ($\sqrt{R^2}$). Геометрически скалярное произведение можно изобразить как произведение длин одного из векторов на проекцию второго вектора на первый. Если будет проецировать $y-\bar y\v1$ на $\hy-\bar y\v1$, то получим как раз $ESS$ — тот квадрат на рисунке, что уже построен.


$\sCov(\hy, y)=\sqrt{ESS^2/(n-1)^2}=ESS/(n-1)$


\end{sol}
\end{problem}


\begin{problem}
Предложите аналог $R^2$ для случая, когда константа среди регрессоров отсутствует. Аналог должен быть всегда в диапазоне $[0;1]$, совпадать с обычным $R^2$, когда среди регрессоров есть константа, равняться единице в случае нулевого $\he$.


\begin{sol}
Спроецируем единичный столбец на «плоскость», обозначим его $1'$. Делаем проекцию $y$ на «плоскость» и на $1'$. Далее аналогично.
\end{sol}
\end{problem}



\begin{problem}
Вася оценил регрессию $y$ на константу, $x$ и $z$. А затем, делать ему нечего, регрессию $y$ на константу и полученный $\hy$. Какие оценки коэффициентов у него получатся? Чему будет равна оценка дисперсии коэффицента при $\hy$? Почему оценка коэффициента неслучайна, а оценка её дисперсии положительна?


\begin{sol}
Проекция $y$ на $\hy$ это $\hy$, поэтому оценки коэффициентов будут 0 и 1. Оценка дисперсии $\frac{RSS}{(n-2)ESS}$. Нарушены предпосылки теоремы Гаусса-Маркова, например, ошибки новой модели в сумме дают 0, значит коррелированы.
\end{sol}
\end{problem}




\begin{problem}
При каких условиях $TSS=ESS+RSS$?

\begin{sol}
Либо в регрессию включена константа, либо единичный столбец (тут была опечатка, столбей) можно получить как линейную комбинацию регрессоров, например, включены дамми-переменные для каждого возможного значения качественной переменной.
\end{sol}
\end{problem}


\begin{problem}
Вася построил парную регрессию $y$ на $x$ и получил коэффициент наклона $1.4$. Построил парную регрессию $x$ на $y$ и получил коэффициент наклона $0.6$. Известно, что $y=x+z$.
\begin{enumerate}
    \item Найдите выборочные корреляции между $x$ и $y$, $y$ и $z$, $x$ и $z$;
    \item В какой пропорции соотносятся выборочные дисперсии $x$, $y$ и $z$?
\end{enumerate}
\begin{sol}
\end{sol}
\end{problem}


\section{Распределения, связанные с проецированием}

\begin{problem}
Компоненты вектора $x=(x_1, x_2)'$ независимы и имеют стандартное нормальное распределение. Вектор $y$ задан формулой $y = (2x_1 + x_2 + 2, x_1 - x_2 - 1)$.
\begin{enumerate}
  \item Выпишите совместную функцию плотности вектора $x$;
  \item Нарисуйте на плоскости линии уровня функции плотности вектора $x$;
  \item Выпишите совместную функцию плотности вектора $y$;
  \item Найдите собственные векторы и собственные числа ковариационной матрицы вектора $y$;
  \item Нарисуйте на плоскости линии уровня функции плотности вектора $y$.
\end{enumerate}
\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Компоненты вектора $x=(x_1, x_2, x_3)'$ независимы и имеют стандартное нормальное распределение.

\begin{enumerate}
\item Как выглядят в пространстве поверхности уровня совместной функции плотности?
\item Рассмотрим три апельсина с кожурой одинаковой очень маленькой толщины: бэби-апельсин радиуса $0.1$, стандартный апельсин радиуса $1$ и гранд-апельсин радиуса $10$. В кожуру какого апельсина вектор $x$ попадает с наибольшей вероятностью?
\item Мы проецируем случайный вектор на $x$ на плоскость $2x_1 + 3x_2 - 7x_3 = 0$. Какое распределение имеет квадрат длины проекции?
\item Введём вектор $y$ независимый от $x$ и имеющий такое же распределение. Спроецируем вектор $x$ на плоскость проходящую через начало координат и перпендикулярную вектору $y$.  Какое распределение имеет квадрат длины проекции?
\end{enumerate}


\begin{sol}
Сферы с центром в начале координат. Проекция имеет хи-квадрат распределение с тремя степенями свободы.
Для нахождения максимальной вероятности максимизируем функцию
\[
\exp(-R^2/2) \cdot ((R+t)^3 - R^3) \to \max_R
\],
где $R$ — радиус мякоти, а $t$ — толщина кожуры апельсина. Оставляем только линейную часть по $t$ и затем максимизируем.

Наибольшая вероятность попасть в апельсин радиуса $R=1$.
\end{sol}
\end{problem}


\section{Ожидания и ковариационные матрицы}


\begin{problem}
Исследовательница Мишель собрала данные по 20 студентам. Переменная $y_i$ — количество решённых задач по эконометрике $i$-ым студентом, а $x_i$ — количество просмотренных серий любимого сериала за прошедший год. Оказалось, что $\sum y_i = $, $\sum x_i = $, $\sum x_i^2 = $, $\sum y_i^2 = $, $\sum x_i y_i = $.

\begin{enumerate}
\item

\item Предположим дополнительно, что $\Var(u_i|X)=\sigma^2$ и $u_i$ при фиксированных $X$ независимы. Найдите $\Var(y_i|X)$, $\Var(y_i (x_i - \bar x)|X)$, $\Var(\sum y_i (x_i - \bar x)|X)$, $\Var(\hb_2 | X)$.

\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Пусть регрессионная модель $y_i = \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \e_i$, $i = 1, \ldots, n$, задана в матричном виде при помощи уравнения $y = X \beta + \e$, где $\beta =  \begin{pmatrix}
\beta_1 & \beta_2 & \beta_3\\
\end{pmatrix} '$. Известно, что $\E \e = 0$ и $\Var (\e) = 4 \cdot I$. Известно также, что:

$y =  \begin{pmatrix}
1 \\
2 \\
3 \\
4 \\
5 \\
\end{pmatrix} $, $X =  \begin{pmatrix}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 \\
\end{pmatrix} $

Для удобства расчётов ниже приведены матрицы:

$X' X =  \begin{pmatrix}
5 & 3 & 1 \\
3 & 3 & 1 \\
1 & 1 & 1 \\
\end{pmatrix} $ и $(X' X)^{-1} =  \begin{pmatrix}
0.5 & -0.5 & 0 \\
-0.5 & 1 & -0.5 \\
0 & -0.5 & 1.5 \\
\end{pmatrix} $.


\begin{enumerate}
\item Найдите $\E (\hs^2)$, $\hs^2$.
\item Найдите $\Var (\e_1)$, $\Var (\beta_1)$, $\Var (\hb_1)$, $\hVar(\hb_1)$, $\E (\hb_1^2) - \beta_1^2$;
\item Предполагая нормальность ошибок, постройте $95\%$ доверительный интервал для $\beta_2$.
\item Предполагая нормальность ошибок, проверьте гипотезу $H_0$: $\beta_2 = 0$;
\item Найдите $\Cov (\hb_2, \hb_3)$, $\hCov(\hb_2, \hb_3)$, $\Var (\hb_2 - \hb_3)$, $\hVar(\hb_2 - \hb_3)$;
\item Найдите $\Var (\beta_2 - \beta_3)$, $\Corr (\hb_2, \hb_3)$, $\hCorr(\hb_2, \hb_3)$;
\item Предполагая нормальность ошибок, проверьте гипотезу $H_0$: $\beta_2 = \beta_3$;
\end{enumerate}


\begin{sol}
\begin{enumerate}
\item $\Var(\e_1)=\Var(\e)_{(1,1)}=4\cdot I_{(1,1)}=4$
\item $\Var(\beta_1)=0$, так как $\beta_1$ — детерминированная величина.
\item $\Var(\hb_1)=\sigma^2(X'X)^{-1}_{(1,1)}=0.5\sigma^2=0.5\cdot 4=2$
\item $\hVar(\hb_1)=\hat\sigma^2(X'X)^{-1}_{(1,1)}=0.5\hat\sigma^2_{(1,1)}=0.5\frac{RSS}{5-3}=0.25RSS=0.25y'(I-X(X'X)^{-1}X')y=0.25\cdot 1=0.25$

$\hat\sigma^2=\frac{RSS}{n-k}=\frac12$.

\item Так как оценки МНК являются несмещёнными, то $\E(\hb)=\beta$, значит:
\[
\E(\hb_1)-\beta_1^2=\E(\hb_1)-(\E(\hb_1))^2=\hVar(\hb_1)=0.25
\]

\item $\Cov(\hb_2,\hb_3)=\sigma^2(X'X)^{-1}_{(2,3)}=4\cdot\left(-\frac12\right)=-2$
\item $\hCov(\hb_2,\hb_3)=\hVar(\hat\beta)_{(2,3)}=\hat\sigma^2(X'X)^{-1}_{(2,3)}=\frac{1}{2}\cdot\left(-\frac12\right)=-\frac14$

\item $\Var(\hb_2-\hb_3)=\Var(\hb_2)+\Var(\hb_3)+2\Cov(\hb_2,\hb_3)=\sigma^2((X'X)^{-1}_{(2,2)}+(X'X)^{-1}_{(3,3)}+2(X'X)^{-1}_{(2,3)}=4(1+1.5+2\cdot(-0.5))=6$

\item $\hVar(\hb_2-\hb_3)=\hVar(\hb_2)+\hVar(\hb_3)+2\hCov(\hb_2,\hb_3)=\hat\sigma^2((X'X)^{-1}_{(2,2)}+(X'X)^{-1}_{(3,3)}+2(X'X)^{-1}_{(2,3)}=\frac{1}{2}\cdot1.5=0.75$

\item $\Var(\beta_2-\beta_3)=0$

\item $\corr(\hb_2,\hb_3)=\frac{\Cov(\hb_2,\hb_3)}{\sqrt{\Var(\hb_2)\Var(\hb_3)}}=\frac{-2}{\sqrt{4\cdot6}}=-\frac{\sqrt6}{6}$

\item $\hCorr(\beta_2,\beta_3)=\frac{\hCov(\hb_2,\hb_3)}{\sqrt{\hVar(\hb_2)\hVar(\hb_3)}}=\frac{-\frac14}{\sqrt{\frac12\cdot\frac34}}=-\frac{\sqrt6}{6}$

\item $(n-k)\frac{\hat\sigma^2}{\sigma^2}\sim\chi^2_{n-k}$.
\[
\E\left((n-k)\frac{\hat\sigma^2}{\sigma^2}\right)=n-k
\]
\[
\E\left(\frac{\hat\sigma^2}{2}\right)=1
\]
\[
\E(\hat\sigma^2)=2
\]

\item $\hat\sigma^2=\frac{RSS}{n-k}=\frac12$

\end{enumerate}

\end{sol}
\end{problem}



\section{Гипотезы и интервалы}





\section{Гамма, бета}

\begin{problem}
Вася делает эксперименты без устали со скоростью $d$ экспериментов в минуту. Каждый эксперимент независимо от других может окончится успехом с вероятностью $p$ или неудачей.

Пусть $X$ — количество успехов за первую минуту, а $Y$ — номер опыта, в котором произошёл первый успех, $Z$ — время, когда случился первый успех.
\begin{enumerate}
\item Найдите $\P(X = k)$, $\E(X)$, $\Var(X)$. Как называется закон распределения $X$?
\item Найдите $\P(Y = k)$, $\E(Y)$, $\Var(Y)$. Как называется закон распределения $Y$?
\item Найдите $\P(Z \leq t)$, $\E(Z)$, $\Var(Z)$.
\end{enumerate}

Теперь Вася ускоряется и устремляет $d$ в бесконечность. Из-за того, что он торопится, $p$ начинает стремится к нулю :) Причем ожидаемое количество успехов за минуту оказывается постоянно и равно $\lambda$.

\begin{enumerate}[resume]
\item Выразите $p$ через $\lambda$ и $d$.
\item Найдите предел $\P(Z \leq t)$. Является ли предельная функция $\P(Z \leq t)$ непрерывной? Какая в предельном случае получается функция плотности у величины $Z$? Как называется этот закон распределения $Z$? Чему равен предел $\E(Z)$ и $\Var(Z)$?
\item Найдите предел вероятности $\P(X = k)$ и пределы $\E(X)$ и $\Var(X)$. Как называется предельный закон распределения $X$?
\end{enumerate}
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
    Энтомолог Джон Поллак ловит бабочек. На поимку $i$-ой бабочки у него уходит $Y_i$ минут, величины $Y_i$ независимы. Каждая $Y_i$ имеет экспоненциальное распределение с интенсивностью $\lambda$ бабочек в минуту. Всего он решил поймать $n$ бабочек. Рассмотрим величины $S=Y_1 + \ldots + Y_n$, $X_1 = Y_1 / S$, $X_2 = Y_2/S$, \ldots, $X_{n-1}=Y_{n-1}/S$.

\begin{enumerate}
    \item Выпишите совместную функцию плотности $Y_1$, \ldots, $Y_n$;
    \item Найдите совместную функцию плотности $X_1$, $X_2$, $X_3$, \ldots, $X_{n-1}$, $S$.
    \item Зависит ли величина $S$ и вектор $X_1$, $X_2$, \ldots, $X_{n-1}$?
    \item С точностью до сомножителя выпишите функцию плотности $S$. Как называется закон распределения $S$?
    \item С точностью до сомножителя выпишите совместную функцию плотности для $X_1$, \ldots, $X_{n-1}$.
\end{enumerate}

Рассмотрим также величины $Z_1 = Y_1 / (Y_1 + Y_2)$, $Z_2 = (Y_1 + Y_2) / (Y_1 + Y_2 + Y_3)$, \ldots, $Z_{n-1} = (Y_1 + \ldots + Y_{n-1}) / (Y_1 + \ldots + Y_n)$.

\begin{enumerate}[resume]
    \item Найдите совместную функцию плотности $Z_1$, $Z_2$, \ldots, $Z_{n-1}$, $S$.
    \item Зависимы ли величины $Z_1$, $Z_2$, \ldots, $Z_{n-1}$, $S$?
    \item С точностью до константы найдите частную функцию плотности $S$ и каждого $Z_i$ в отдельности;
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}





\begin{problem}
    Быстрый исследователь Вася снова проводит независимые идентичные опыты с очень высокой скоростью. В среднем $\lambda$ опытов в минуту оказываются успешными. Поэтому время до очередного успеха можно считать экспоненциально распределённым, а время от начала до $k$-го успеха — имеющим гамма-распределение $Gamma(k, \lambda)$. На этот раз Вася решил дождаться $k_1$ успеха, затем быстренько пообедать, а затем дождаться ещё $k_2$ успехов. Пусть $X_1$ — время от начала наблюдения до обеда, а $X_2$ — время от обеда до конца опытов. Также введём $S=X_1 + X_2$ и $Z = X_1 / S$ — долю времени до обеда от общего времени набопытов.

\begin{enumerate}
    \item Найдите совместную функцию плотности $S$ и $Z$ с точностью до константы.
    \item Являются ли $S$ и $Z$ независимыми случайными величинами?
    \item Найдите частные функции плотности $S$ и $Z$.
    \item Как называется закон распределения $S$?
        \item Как называется закон распределения $Z$?
    \item Какой закон распределения имеет величина $W = 1 - Z$?
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}



\begin{problem}
    yyy
\begin{sol}
\end{sol}
\end{problem}




\begin{problem}
    Вася оценивает регрессию $y$ на регрессоры $X$, включающие константу, а на самом деле все коэффициенты $\beta_j$ кроме константы равны нулю. Ошибки $u_i$ распределены нормально $\cN(0;\sigma^2)$. Какое распределение имеет $R^2$?
\begin{sol}
\end{sol}
\end{problem}


% \section{Хочу ещё задач!}

\section{Максимально правдоподобно}

\begin{problem}
  Величины $y_1$, $y_2$, \ldots, $y_n$ независимы и экспоненциально распределены с параметром $\lambda$. По выборке из $100$ наблюдений оказалось, что $\sum y_i=200$. Исследователь Андреас хочет проверить гипотезу $H_0$: $\E(y_i)=1$ против альтернативной $\E(y_i)\neq 1$.

\begin{enumerate}
  \item Выпишите логарифмическую функцию правдоподобия $\ell(\lambda)$;
  \item Найдите оценку $\hat \lambda$ методом максимального правдоподобия
    в общем виде и для имеющейся выборки;
  \item Найдите теоретическую информацию Фишера $I(\lambda)$ для $n$ наблюдений;
  \item Выведите формулы для статистик отношения правдоподобия, множителей Лагранжа и Вальда в общем виде;
  \item Найдите значения статистик отношения правдоподобия, множителей Лагранжа и Вальда для имеющейся выборки;
  \item Проверьте гипотезу $H_0$ с помощью трёх статистик.
\end{enumerate}     
  \begin{sol}
    $\ell'(\lambda)=\frac{n}{\lambda} - \sum y_i$; $I(\lambda)=n/\lambda^2$
  \end{sol}
\end{problem}



\begin{problem}
  Рассмотрим модель простой регрессии $y_i = \beta x_i + u_i$, где ошибки $u_i$ независимы и имеют стандартное нормальное распределение, $u_i \sim \cN(0;1)$. По выборке из 100 наблюдений оказалось, что $\sum x_i^2 = 100$, а $\sum y_i x_i  = 250$. Исследователь Рамирес хочет проверить $H_0$: $\beta=0$.


\begin{enumerate}
  \item Выпишите логарифмическую функцию правдоподобия $\ell(\beta)$;
  \item Найдите оценку $\hat \beta$ методом максимального правдоподобия
    в общем виде и для имеющейся выборки;
  \item Найдите теоретическую информацию Фишера $I(\beta)$ для $n$ наблюдений;
  \item Выведите формулы для статистик отношения правдоподобия, множителей Лагранжа и Вальда в общем виде;
  \item Найдите значения статистик отношения правдоподобия, множителей Лагранжа и Вальда для имеющейся выборки;
  \item Проверьте гипотезу $H_0$ с помощью трёх статистик.
\end{enumerate}     

  \begin{sol}

  \end{sol}
\end{problem}









\Closesolutionfile{solution_file}


% для гиперссылок на условия
% http://tex.stackexchange.com/questions/45415
\renewenvironment{solution}[1]{%
         % add some glue
         \vskip .5cm plus 2cm minus 0.1cm%
         {\bfseries \hyperlink{problem:#1}{#1.}}%
}%
{%
}%

\section{Решения}
\input{all_solutions}

\section{Источники мудрости}
\printbibliography[heading=none]


\end{document}
