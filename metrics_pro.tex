\documentclass[11pt, a4paper]{article}

% If you can't see cyrillic letters in R-studio choose
% File-Reopen with encoding
% utf8 is the preferred encoding


\input{title_bor_utf8_knitr}
\input{emetrix_preamble}




\usepackage[bibencoding = auto, backend = biber,
sorting = none]{biblatex}

\addbibresource{metrics_pro.bib}

\def \RR{\mathbb{R}}
\def \cN{\mathcal{N}}
\def \htheta{\hat{\theta}}

\title{Заметки к семинарам по эконометрике}
\author{Винни-Пух}
\date{\today}


% делаем короче интервал в списках
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}


\DeclareMathOperator{\Med}{Med}


\usepackage{answers} % дележка условий и ответов

%\newtheorem{problem}{Задача}
%\numberwithin{problem}{section}

\Newassociation{sol}{solution}{solution_file}
% sol — имя окружения внутри задач
% solution — имя окружения внутри solution_file
% solution_file — имя файла в который будет идти запись решений
% можно изменить далее по ходу
\Opensolutionfile{solution_file}[all_solutions]
% в квадратных скобках фактическое имя файла


% магия для автоматических гиперссылок задача-решение
\newlist{myenum}{enumerate}{3}
% \newcounter{problem}[chapter] % нумерация задач внутри глав
\newcounter{problem}

\newenvironment{problem}%
{%
\refstepcounter{problem}%
%  hyperlink to solution
     \hypertarget{problem:{\thesection.\theproblem}}{} % нумерация внутри глав
     % \hypertarget{problem:{\theproblem}}{}
     \Writetofile{solution_file}{\protect\hypertarget{soln:\thesection.\theproblem}{}}
     %\Writetofile{solution_file}{\protect\hypertarget{soln:\theproblem}{}}
     \begin{myenum}[label=\bfseries\protect\hyperlink{soln:\thesection.\theproblem}{\thesection.\theproblem},ref=\thesection.\theproblem]
     % \begin{myenum}[label=\bfseries\protect\hyperlink{soln:\theproblem}{\theproblem},ref=\theproblem]
     \item%
    }%
    {%
    \end{myenum}}
% для гиперссылок обратно надо переопределять окружение
% это происходит непосредственно перед подключением файла с решениями





\begin{document}

% \maketitle % ставим сюда название, автора и время создания

\section{МНК — это\ldots}

Минитеория:

\begin{enumerate}
\item Истинная модель. Например, $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + u_i$.
\item Формула для прогнозов. Например, $\hy_i = \hb_1 + \hb_2 x_i + \hb_3 z_i$.
\item Метод наименьших квадратов, $\sum (y_i - \hy_i)^2 \to \min$.
\end{enumerate}

Задачи:
\begin{problem}
Каждый день Маша ест конфеты и решает задачи по эконометрике. Пусть $x_i$ — количество решённых задач, а $y_i$ — количество съеденных конфет.

\begin{tabular}{cc}
\toprule
$x_i$ & $y_i$ \\
\midrule
1 & 1 \\
2 & 2 \\
2 & 4 \\
\bottomrule
\end{tabular}

\begin{enumerate}
\item Рассмотрим модель $y_i = \beta x_i + u_i$:
\begin{enumerate}
\item Найдите МНК-оценку $\hb$ для имеющихся трёх наблюдений.
\item Нарисуйте исходные точки и полученную прямую регрессии.
\item Выведите формулу для $\hb$ в общем виде для $n$ наблюдений.
\end{enumerate}

\item Рассмотрим модель $y_i = \beta_1 + \beta_2 x_i + u_i$:
\begin{enumerate}
\item Найдите МНК-оценки $\hb_1$ и $\hb_2$ для имеющихся трёх наблюдений.
\item Нарисуйте исходные точки и полученную прямую регрессии.
\item Выведите формулу для $\hb_2$ в общем виде для $n$ наблюдений.
\end{enumerate}

\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Упростите выражения:
\begin{enumerate}
\item $n\bar x - \sum x_i$
\item $\sum (x_i - \bar x)\bar x$
\item $\sum (x_i - \bar x)\bar z$
\item $\sum (x_i - \bar x)^2 + n \bar{x}^2$
\end{enumerate}

\begin{sol}
Ответы: $0$, $0$, $0$, $\sum x_i^2$.
\end{sol}
\end{problem}


\begin{problem}
При помощи метода наименьших квадратов найдите оценку неизвестного параметра $\theta$ в следующих моделях:

\begin{enumerate}
\item $y_i = \theta + \theta x_i + \varepsilon_i$;
\item $y_i = 1 + \theta x_i + \e_i$;
\item $y_i = \theta / x_i + \e_i$;
\item $y_i = \theta x_i + (1-\theta)z_i+\e_i$.
\end{enumerate}

\begin{sol}
\begin{enumerate}
\item \(\htheta = \sum \left((y_i - z_i)(x_i - z_i) \right) / \sum \left(x_i - z_i\right)^2 \)
\end{enumerate}
\end{sol}
\end{problem}

\begin{problem}
Найдите МНК-оценки параметров $\alpha$ и $\beta$ в модели $y_i = \alpha + \beta y_i + \e_i$.


\begin{sol}
\(\hat{\alpha} = 0, \ \hb = 1 \)
\end{sol}
\end{problem}


\begin{problem}
Рассмотрите модели $y_i = \alpha + \beta (y_i + z_i) + \e_i$, $z_i = \gamma + \delta(y_i+z_i) + \e_i$.
\begin{enumerate}
\item Как связаны между собой $\hat{\alpha}$ и $\hat{\gamma}$?
\item Как связаны между собой $\hb$ и $\hat{\delta}$?
\end{enumerate}


\begin{sol} % 1.5.
Рассмотрим регрессию суммы $(y_i + z_i)$ на саму себя. Естественно, в ней
\[
\widehat{y_i + z_i} = 0 + 1 \cdot (y_i + z_i).
\]

Отсюда получаем, что $\hat{\alpha} + \hat{\gamma} = 0$ и $\hb + \hat{\delta} = 1$.
\end{sol}
\end{problem}




\begin{problem}
Как связаны МНК-оценки параметров $\alpha, \beta$ и $\gamma, \delta$ в моделях $y_i = \alpha + \beta x_i + \e_i$ и $z_i = \gamma + \delta x_i + \upsilon_i$, если $z_i = 2 y_i$?


\begin{sol}

Исходя из условия, нужно оценить методом МНК коэффициенты двух следующих моделей:
\[y_i = \alpha + \beta x_i + \e_i \]
\[y_i = \frac{\gamma}{2} + \frac{\delta}{2} x_i + \frac{1}{2} v_i \]

Заметим, что на минимизацию суммы квадратов остатков коэффициент \(1/2\) не влияет, следовательно:
\[\hat{\gamma} = 2\hat{\alpha}, \ \hat{\delta} = 2 \hb  \]

\end{sol}
\end{problem}


\begin{problem}
Для модели $y_i = \beta_1 x_i + \beta_2 z_i + \e_i$ решите условную задачу о наименьших квадратах:
\[
Q(\beta_1, \beta_2) := \sum_{i=1}^n (y_i - \hb_1 x_i - \hb_2 z_i)^2 \rightarrow \underset{\beta_1 + \beta_2 = 1}{\min}.
\]


\begin{sol}
Выпишем задачу:
\[
\begin{cases}
RSS = \sum\limits_{i=1}^{n}(y_i - \hb_1x_i - \hb_2z_i)^2 \rightarrow \min\limits_{\hb_1, \hb_2}\\
\hb_1 + \hb_2 = 1
\end{cases}
\]

Можем превратить ее в задачу минимизации функции одного аргумента:
\[
RSS =  \sum\limits_{i=1}^{n}(y_i - x_i - \hb_2(z_i-x_i))^2 \rightarrow \min_{\hb_2}
\]

Выпишем условия первого порядка:
\[
\frac{\partial RSS}{\partial \hb_2} = \sum\limits_{i=1}^{n}2(y_i-x_i-\hb_2(z_i-x_i))(x_i-z_i)=0
\]

Отсюда:
\[
\sum\limits_{i=1}^{n}(y_i-x_i)(x_i-z_i) + \hb_2\sum\limits_{i=1}^{n}(z_i-x_i)^2 = 0 \Rightarrow \hb_2 = \frac{\sum\limits_{i=1}^n (y_i-x_i)(z_i-x_i)}{\sum\limits_{i=1}^n (z_i-x_i)^2}
\]

А $\hb_1$ найдется из соотношения $\hb_1+\hb_2 = 1$.

\end{sol}
\end{problem}

\begin{problem}
Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток — $200$ грамм, взвесив оба слитка — $400$ грамм. Оцените вес каждого слитка методом наименьших квадратов.

\begin{sol}
Обозначив вес первого слитка за \(\beta_1\), вес второго слитка за \(\beta_2\), а показания весов за \(y_i\), получим, что
\[y_1 = \beta_1 + \e_1, \ y_2 = \beta_2 + \e_2, \ y_3 = \beta_1 + \beta_2 + \e_3\]

Тогда
\[(300 - \beta_1)^2 + (200 - \beta_2)^2 + (400 - \beta_1 - \beta_2)^2 \rightarrow \min \limits_{\beta_1,\  \beta_2} \]
\[\hb_1 = \frac{800}{3}, \ \hb_2 = \frac{500}{3} \]
\end{sol}
\end{problem}


\begin{problem}
Аня и Настя утверждают, что лектор опоздал на 10 минут. Таня считает, что лектор опоздал на 3 минуты. С помощью МНК оцените, на сколько опоздал лектор.

\begin{sol}
Можем воспользоваться готовой формулой для регрессии на константу:
\[
\hb = \bar{y} = \frac{10+10+3}{3} = \frac{23}{3}
\]

(можно решить задачу $2(10-\beta)^2 + (3-\beta)^2\rightarrow \min$)

\end{sol}
\end{problem}

\begin{problem}
Есть двести наблюдений. Вовочка оценил модель $\hy=\hb_1+\hb_2 x$ по первой сотне наблюдений. Петечка оценил модель $\hy=\hat{\gamma}_1+\hat{\gamma}_2 x$ по второй сотне наблюдений. Машенька оценила модель $\hy=\hat{m}_1+\hat{m}_2 x$ по всем наблюдениям.
\begin{enumerate}
\item Возможно ли, что $\hb_2>0$, $\hat{\gamma}_2>0$, но $\hat{m}_2<0$?
\item Возможно ли, что $\hb_1>0$, $\hat{\gamma}_1>0$, но $\hat{m}_1<0$?
\item Возможно ли одновременное выполнение всех упомянутых условий?
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
У эконометриста Вовочки есть переменная $1_f$, которая равна 1, если $i$-ый человек в выборке — женщина, и 0, если мужчина. Есть переменная $1_m$, которая равна 1, если $i$-ый человек в выборке — мужчина, и 0, если женщина. Вовочка попробовал оценить 4 регрессии.
\begin{enumerate}
\item $y$ на константу и $1_f$;
\item $y$ на константу и $1_m$;
\item $y$ на $1_f$ и $1_m$ без константы;
\item $y$ на константу, $1_f$ и $1_m$.
\end{enumerate}

\begin{enumerate}
\item Какой смысл будут иметь оцениваемые коэффициенты?
\item Как связаны между собой оценки коэффициентов этих регрессий?
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Эконометрист Вовочка оценил методом наименьших квадратов модель 1, $y=\b_1+\b_2 x+\b_3 z+\e$, а затем модель 2, $y=\b_1+\b_2 x+\b_3 z+\b_4 w+\e$. Сравните полученные $ESS$, $RSS$, $TSS$ и $R^2$.

\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Что происходит с $TSS$, $RSS$, $ESS$, $R^2$ при добавлении нового наблюдения? Если величина может изменяться только в одну сторону, то докажите это. Если возможны и рост, и падение, то приведите пример.


\begin{sol}
Пусть \(\bar{y}\) — средний \(y\) до добавления нового наблюдения, \(\bar{y}'\) — после добавления нового наблюдения. Будем считать, что изначально было \(n\) наблюдений. Заметим, что
\[\bar{y}' = \frac{(y_1 + \ldots + y_n) + y_{n+1}}{n + 1} = \frac{n \bar{y} + y_{n + 1}}{n + 1} = \frac{n}{n+ 1}\bar{y} + \frac{1}{n+1}y_{n+1}\]

Покажем, что \(TSS\) может только увеличится при добавлении нового наблюдения (остается неизменным при \(y_{n+1} = \bar{y}\)):
\[TSS'= \sum_{i = 1}^{n + 1} (y_i - \bar{y}')^2 = \sum_{i = 1}^{n} (y_i - \bar{y} + \bar{y} - \bar{y}')^2 + (y_{n + 1} - \bar{y}')^2 = \]
\[=\sum_{i = 1}^{n} (y_i - \bar{y})^2 + n(\bar{y} - \bar{y}')^2 + (y_{n + 1} - \bar{y}')^2  = TSS + \frac{n}{n+1} (y_{n+1} - \bar{y})^2\]

Следовательно, \(TSS' \geqslant TSS\).

Также сумма \(RSS\) может только вырасти или остаться постоянной при добавлении нового наблюдения. Действительно, новое $(n+1)$-ое слагаемое в сумме неотрицательно. А сумма $n$ слагаемых минимальна при старых коэффициентах, а не при новых.

\(ESS\) и \(R^2\) могут меняться в обе стороны. Например, рассмотрим ситуацию, где точки лежат симметрично относительно некоторой горизонтальной прямой. При этом $ESS=0$. Добавим наблюдение — $ESS$ вырастет, удалим наблюдение — $ESS$ вырастет.
\end{sol}
\end{problem}



\begin{problem}
Эконометресса Аглая подглядела, что у эконометрессы Жозефины получился $R^2$ равный $0.99$ по 300 наблюдениям. От чёрной зависти Аглая не может ни есть, ни спать.

\begin{enumerate}
\item Аглая добавила в набор данных Жозефины ещё 300 наблюдений с такими же регрессорами, но противоположными по знаку игреками, чем были у Жозефины. Как изменится $R^2$?
\item Жозефина заметила, что Аглая добавила 300 наблюдений и вычеркнула их, вернув в набор данных в исходное состояние. Хитрая Аглая решила тогда добавить всего одно наблюдение так, чтобы $R^2$ упал до нуля. Удастся ли ей это сделать?
\end{enumerate}


\begin{sol}
\begin{enumerate}
\item $R^2$ упал до нуля.
\item Да, можно. Если добавить точку далеко слева внизу от исходного набора данных, то наклон линии регрессии будет положительный. Если далеко справа внизу, то отрицательный. Будем двигать точку так, чтобы поймать нулевой наклон прямой. Получим $ESS=0$.
\end{enumerate}
\end{sol}
\end{problem}



\section{МНК в матрицах!}

Минитеория.

Дифференциал для матриц подчиняется правилам:

\begin{enumerate}
\item $da = 0$, $dA = 0$;
\item $d(RS) = dR \dot S + R \cdot dS$
\end{enumerate}

\begin{problem}
Пусть $t$ — скалярная переменная, $r$, $s$ — векторные переменные, $R$, $S$ — матричные переменные. Кроме того, $a$, $b$ — векторы констант, $A$, $B$ — матрицы констант.

Применив базовые правила дифференцирования найдите:
\begin{enumerate}
\item $d(ARB)$;
\item $d(r'r)$;
\item $d(r'Ar)$;
\item $d(R^{-1})$, воспользовавшись тем, что $R^{-1} \cdot R = I$;
\item $d \cos(r'r)$;
\item $d(r'Ar/r'r)$.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
В методе наименьших квадратов минимизируется функция
\[
Q(\hb) = (y - X\hb)'(y - X\hb).
\]

\begin{enumerate}
\item Найдите $dQ(\hb)$ и $d^2Q(\hb)$;
\item Выпишите условия первого порядка для задачи МНК;
\item Выразите $\hb$ предполагая, что $X'X$ обратима.
\end{enumerate}


\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
В методе LASSO минимизируется функция
\[
Q(\hb) = (y - X\hb)'(y - X\hb) + \lambda hb' hb,
\]
где $\lambda$ — положительный параметр, штрафующий функцию за слишком большие значения $\hb$.

\begin{enumerate}
\item Найдите $dQ$;
\item Выпишите условия первого порядка для задачи LASSO;
\item Выразите $\hb$.
\end{enumerate}

\begin{sol}
\end{sol}
\end{problem}



\begin{problem}

\begin{sol}
\end{sol}
\end{problem}




\section{Распределение}

\begin{problem}
Компоненты вектора $x=(x_1, x_2)'$ независимы и имеют стандартное нормальное распределение. Вектор $y$ задан формулой $y = (2x_1 + x_2 + 2, x_1 - x_2 - 1)$. 
\begin{enumerate}
  \item Выпишите совместную функцию плотности вектора $x$;
  \item Нарисуйте на плоскости линии уровня функции плотности вектора $x$;
  \item Выпишите совместную функцию плотности вектора $y$;
  \item Найдите собственные векторы и собственные числа ковариационной матрицы вектора $y$;
  \item Нарисуйте на плоскости линии уровня функции плотности вектора $y$. 
\end{enumerate}
\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Компоненты вектора $x=(x_1, x_2, x_3)'$ независимы и имеют стандартное нормальное распределение. 

\begin{enumerate}
\item Как выглядят в пространстве поверхности уровня совместной функции плотности?
\item Какая вероятность для случайного вектора $x$ выше, попасть в кожуру маленькой толщины $d$ у маленького апельсина, или в кожуру маленькой толщины $d$ у большого апельсина?
\item Мы проецируем случайный вектор на $x$ на плоскость $2x_1 + 3x_2 - 7x_3 = 0$. Какое распределение имеет квадрат длины проекции?
\item Введём вектор $y$ независимый от $x$ и имеющий такое же распределение. Спроецируем вектор $x$ на плоскость проходящую через начало координат и перпендикулярную вектору $y$.  Какое распределение имеет квадрат длины проекции? 
\end{enumerate}


\begin{sol}
Сферы с центром в начале координат. Проекция имеет хи-квадрат распределение с тремя степенями свободы.
\end{sol}
\end{problem}


% \section{Хочу ещё задач!}




\Closesolutionfile{solution_file}


% для гиперссылок на условия
% http://tex.stackexchange.com/questions/45415
\renewenvironment{solution}[1]{%
         % add some glue
         \vskip .5cm plus 2cm minus 0.1cm%
         {\bfseries \hyperlink{problem:#1}{#1.}}%
}%
{%
}%

\section{Решения}
\input{all_solutions}

\section{Источники мудрости}
\printbibliography[heading=none]


\end{document}
